{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9132cf96",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "This section scrapes data from Google Images and stores them in different folders/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf7c16c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for automation\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#import for web scrapping\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from os.path import basename\n",
    "import base64\n",
    "\n",
    "#extra imports\n",
    "import traceback\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87aad4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_accumulator:\n",
    "    \n",
    "    def __init__(self, topic, folder):\n",
    "        self.topic = topic\n",
    "        self.folder = folder\n",
    "        self.driver = webdriver.Chrome()\n",
    "        self.driver.get('https://www.google.com')\n",
    "\n",
    "    def topic_image(self):\n",
    "        try:\n",
    "            search = self.driver.find_element(By.CLASS_NAME, 'gLFyf')\n",
    "            search.send_keys(self.topic)\n",
    "            search.send_keys(Keys.RETURN)\n",
    "\n",
    "            image_page = self.driver.find_element(By.LINK_TEXT, 'Images')\n",
    "            image_page.click()\n",
    "\n",
    "            images = self.driver.find_element(By.CLASS_NAME, 'islrc')\n",
    "            return images\n",
    "\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "\n",
    "\n",
    "    def image_download(self):\n",
    "        current_dir = os.getcwd()\n",
    "        if(not(os.path.exists(os.path.join(os.getcwd(), self.folder)))):\n",
    "            os.mkdir(os.path.join(os.getcwd(), self.folder))\n",
    "            os.chdir(os.path.join(os.getcwd(), self.folder))\n",
    "        else:\n",
    "            os.chdir(os.path.join(os.getcwd(), self.folder))\n",
    "        \n",
    "        page = self.topic_image()\n",
    "        i = 0\n",
    "        elements = page.get_attribute('outerHTML') #gives exact HTML content of the element\n",
    "        soup = bs(elements,'html.parser')\n",
    "        img = soup.findAll('img',{\"src\":True, \"height\":True, \"width\":True})\n",
    "        print(f\"Total Images found: {len(img)}\")\n",
    "        \n",
    "        for link in img:\n",
    "            png = link[\"src\"]\n",
    "            if r\"data:image\" in png:\n",
    "                data = png.split(',')[1]\n",
    "                i = i+1\n",
    "                with open(f\"data{i}.png\", \"wb\") as f:\n",
    "                    f.write(base64.b64decode(data))\n",
    "            else:\n",
    "                i = i+1\n",
    "                with open(f\"file{i}.png\", \"wb\") as f:\n",
    "                    f.write(requests.get(png).content)\n",
    "        os.chdir(current_dir)\n",
    "        self.driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e950727",
   "metadata": {},
   "source": [
    "# Image Classifier\n",
    "This section would consist of the Image Classifier model set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db071f5d",
   "metadata": {},
   "source": [
    "## Dataset Creation\n",
    "Creating a pipeline to fetch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5124dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries for the modelling\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9aa0185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13610848943615712845\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9199e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f928de63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2df4e29c",
   "metadata": {},
   "source": [
    "# Driver Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f62cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data_A = data_accumulator(\"dogs\", \"dogs\")\n",
    "    data_A.image_download()\n",
    "    \n",
    "    data_B = data_accumulator(\"cats\", \"cats\")\n",
    "    data_B.image_download()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
